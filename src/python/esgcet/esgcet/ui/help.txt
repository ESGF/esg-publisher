Welcome to ESGPUBLISHER_GUI.  This help file describes usage and commands.

    The function of this GUI is to provide a convenient way to
    extract metadata from a list of directories representing one or more datasets, into a database.
    The directories should relate to one project only. Generate a THREDDS configuration catalog for
    each dataset, and publish the catalogs to a gateway.

Arguments:
    dataset_map: A file mapping dataset_ids to directories, as generated by esgscan_directory.

    directory: Directory path to scan recursively.

    operation: One of:
        --create (default)
        --replace
        --update
        --delete-files
        --rename-files

Options:

    -a aggregate_dimension_name:
        Name of the aggregate dimension. Defaults to 'time'

    -c, --create
        Create and publish a dataset containing the files listed in the directory or dataset map.

    --echo-sql: Echo SQL commands

    --dataset dataset_name:
        String name of the dataset. If specified, all files will belong to the specified dataset,
        regardless of path. If omitted, paths are matched to the directory_format, as specified in the
        configuration file, to determine the dataset name.

    -d, --delete-files
        Delete the files listed in the dataset map or directory, and republish the dataset.
        Note: This differs from the action of esgunpublish, where the entire dataset is deleted on both
        node and gateway. Also note this operation does not affect the physical files, just the node
        database entries.

    --experiment experiment_id:
        Experiment identifier. All datasets will have this experiment ID, regardless of informtion
        in the dataset map or directory names.

    --filter regular_expression:
        Filter files matching the regular expression. The default is '.*\.nc$'
        Regular expression syntax is defined by the Python re module.

    -h, --help: Print a help message.

    -i init_file: Initialization file. If not specified, the default installed init file is read.

    --keep-version:
        Keep the dataset version number the same for an existing dataset. By default the version number
        is incremented by 1. This option is ignored for new datasets.

    --las
        Reinitialize the LAS (Live Access Server). The default is not to reinitialize.

    --log log_file:
        Name of output log file. Overrides the configuration log_filename option. Default is standard output.

    --map dataset_map: Read input from a dataset map, as generated by esgscan_directory.
        The directory arguments are ignored.

    -m, --message comment:
        Comment to associate with the latest version of the dataset(s). If no new version
        is created, the comment is ignored.

    --model model_id:
        Model identifier. All datasets will have this model ID, regardless of informtion
        in the dataset map or directory names.

    --new-version version_number
        Specify the dataset version number, a positive integer. If unspecified, the version number is
        set to 1 for new datasets, and is incremented by 1 for existing datasets. Use this option
        with caution, as the version number will apply to all datasets processed. See --keep-version.

    --noscan
        Skip the scan phase and just publish. Assumes that the scan has already been done!

    --offline
        The datasets are offline. A minimal amount of information is published, including file size.
        The datafiles are not scanned, and no aggregations are published.

        Note: The project_id and dataset_id must be specified with this option (see --project and
        --dataset).

    -p, --property 'name=value':
        Add a property/value pair. This option can be used multiple times.

        Note: the property must also be configured in the initialization file
        and project handler.

    --parent parent_id:
        Name of the parent dataset of ALL the datasets. If not specified, the parent identifier is generated
        for each dataset from the parent_id option of the initialization file. Use this option with caution.

    --per-time
    --per-variable
        Specify how THREDDS catalogs are generated. If per variable, create a dataset and aggregation for
        each variable. If per time, all variables are contained in a single dataset. The options are
        mutually exclusive, and override the configuration option 'variable_per_file'. Offline datasets
        are always written as per time.

    --project project_id:
        Project identifier. If not specified, the project is determined from the dataset map
        if the --map form is used, otherwise the project is determined from the first file found
        that matches the file filter (see --filter).

        Note: This option is mandatory for offline datasets.

    --publish
        Publish the dataset if there are no errors. Implies --thredds.

    -e, --read-directories:
        Read dataset identification information from the directory
        names. THIS ASSUMES THAT EACH FILE IN A LEAF DIRECTORY BELONGS
        TO THE SAME DATASET. See --read-files, and Notes. This option
        is the default, and is generally faster than --read-files.

    --read-files:
        Read dataset identification information from each individual
        file. If not set, the dataset ID is generated by matching the
        directory with the config file option 'directory_format'.  See
        --read-directories and Notes.

    --rename-files
        Rename one or more files in a dataset. The --map form of the command must be used, and each
        line of the dataset map should have the form:

            dataset_id | to_file | size_in_bytes  | *from_file*=path

    -r, --replace
        Replace the dataset. If the dataset exists, all file entries not in the 'new' dataset are removed,
        existing files are replaced, and new files are added. If the dataset does not exist, the operation
        is the same as --create.

    --replica master_gateway_id
        Flag the dataset(s) as replicated. The argument is the identifier of the gateway where the dataset
        originated, for example, "ESG-PCMDI" or "ESG-NCAR".

    --service service_name
        Specify a THREDDS service name to associate with an offline dataset. If omitted, the name of the
        first offline service in the configuration ''thredds_offline_services'' is used. This determines
        which offline lister to use.

    --summarize-errors
        Print a summary of errors for each dataset scanned.

    --thredds
        Generate THREDDS files.

    -u, --update
        If a dataset exists, update (replace or append) listed files
        to the dataset. If the --map form of the command is used, each
        line of the dataset map has the form:

            dataset_id | to_file | size_in_bytes [ | *from_file*=path]

        If from_file is specified, the file from_file is replaced by to_file. If from_file is not specified,
        the file to_file replaces the dataset file with the same path. Note: in contrast to --replace,
        any existing file entries not in the 'new' dataset remain in the dataset.

    --use-existing dataset_name
        Run the scan phase based on dataset and file information already in the database.
        This option may be used more than once. Compare with --map, which takes a mapfile.
        To republish an existing or older version, specify the dataset as dataset_name#version.

    --use-list filelist
        Like --use-existing, but read the list of dataset names from a
        file, containing one dataset name per line. If the filelist is '-',
        read from standard input.


